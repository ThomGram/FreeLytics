import unittest

from scrapy.http import HtmlResponse
from scrapy_freework.spiders.freework_spider import FreeworkSpider


class TestFreeworkSpiderParsing(unittest.TestCase):
    """Tests for HTML parsing functionality in FreeworkSpider."""

    def setUp(self):
        """Set up test fixtures."""
        self.spider = FreeworkSpider()

    def _create_response(self, html_content, url="http://example.com"):
        """Helper to create a Scrapy response from HTML string."""
        return HtmlResponse(url=url, body=html_content.encode("utf-8"), encoding="utf-8")

    def test_get_icon_field_mapping(self):
        """Test that icon field mapping contains expected mappings."""
        mapping = self.spider.get_icon_field_mapping()

        # Check that all expected field types are present
        expected_fields = {
            "start_date",
            "duration",
            "salary",
            "experience",
            "remote_work",
            "location",
        }
        actual_fields = set(mapping.values())

        self.assertEqual(expected_fields, actual_fields)

        # Check that mapping has correct number of entries
        self.assertEqual(len(mapping), 6)

        # Check specific mappings exist
        self.assertIn("start_date", mapping.values())
        self.assertIn("salary", mapping.values())
        self.assertIn("location", mapping.values())

    def test_parse_job_listings(self):
        """Test parsing of job listing pages."""
        html_content = """
        <html>
        <body>
            <div class="mb-4 relative">
                <a href="/fr/tech-it/data-scientist/job-mission/test-job-1">Job 1</a>
            </div>
        </body>
        </html>
        """
        response = self._create_response(html_content)

        # Get all requests generated by parse method
        requests = list(self.spider.parse(response))

        # Should generate one request for the job detail page
        self.assertEqual(len(requests), 1)

        request = requests[0]
        self.assertEqual(
            request.url, "http://example.com/fr/tech-it/data-scientist/job-mission/test-job-1"
        )
        self.assertEqual(request.callback, self.spider.parse_job_detail)

    def test_icon_field_mapping_functionality(self):
        """Test that icon mapping method works correctly."""
        mapping = self.spider.get_icon_field_mapping()

        # Test with actual salary icon path
        salary_path = "M88 32C39.4 32 0 71.4 0 120V392c0 48.6 39.4 88 88 88H424c48.6 0 88-39.4 88-88V216c0-48.6-39.4-88-88-88H120c-13.3 0-24 10.7-24 24s10.7 24 24 24H424c22.1 0 40 17.9 40 40V392c0 22.1-17.9 40-40 40H88c-22.1 0-40-17.9-40-40V120c0-22.1 17.9-40 40-40H456c13.3 0 24-10.7 24-24s-10.7-24-24-24H88zM384 336a32 32 0 1 0 0-64 32 32 0 1 0 0 64z"

        result = self.spider._match_icon_to_field(salary_path, mapping)
        self.assertEqual(result, "salary")

    def test_salary_processing_methods(self):
        """Test salary processing methods directly."""
        # Test combined salary/TJM
        result = self.spider._process_salary_field("50k-60k €⁄an, 400-500 €⁄j")
        self.assertEqual(result["salary"], "50k-60k €⁄an")
        self.assertEqual(result["daily_rate"], "400-500 €⁄j")

        # Test salary only
        result = self.spider._process_salary_field("50k-60k €⁄an")
        self.assertEqual(result["salary"], "50k-60k €⁄an")
        self.assertEqual(result["daily_rate"], "")

        # Test TJM only
        result = self.spider._process_salary_field("400-500 €⁄j")
        self.assertEqual(result["salary"], "")
        self.assertEqual(result["daily_rate"], "400-500 €⁄j")


if __name__ == "__main__":
    unittest.main()
